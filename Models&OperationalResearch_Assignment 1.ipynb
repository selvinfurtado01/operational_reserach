{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gurobipy import Model, GRB, quicksum\n",
    "from pulp import LpMinimize, LpProblem, LpVariable, lpSum, LpStatus\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "farms_data = pd.read_csv('https://raw.githubusercontent.com/selvinfurtado01/operational_reserach/refs/heads/main/farms.csv')\n",
    "processing_data = pd.read_csv('https://raw.githubusercontent.com/selvinfurtado01/operational_reserach/refs/heads/main/processing.csv')\n",
    "centers_data = pd.read_csv('https://raw.githubusercontent.com/selvinfurtado01/operational_reserach/refs/heads/main/centers.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrected shape of farm_to_plant_costs: (249, 17)\n"
     ]
    }
   ],
   "source": [
    "# Extract key data\n",
    "farm_ids = farms_data['Farm_ID'].tolist()\n",
    "plant_ids = processing_data['Processing_Plant_ID'].tolist()\n",
    "center_ids = centers_data['Center_ID'].tolist()\n",
    "\n",
    "# Define capacities and demands\n",
    "farm_capacities = dict(zip(farm_ids, farms_data['Bio_Material_Capacity_Tons']))\n",
    "processing_capacities = dict(zip(plant_ids, processing_data['Capacity_Tons']))\n",
    "center_demands = dict(zip(center_ids, centers_data['Requested_Demand_Tons']))\n",
    "\n",
    "# Extract costs as matrices\n",
    "farm_to_plant_costs = farms_data.iloc[:, 5:5 + 18].values\n",
    "print(f\"Corrected shape of farm_to_plant_costs: {farm_to_plant_costs.shape}\")\n",
    "plant_to_center_costs = processing_data.iloc[:, 5:5 + len(center_ids)].values\n",
    "processing_costs = dict(zip(plant_ids, processing_data['Processing_Cost_Per_Ton']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing arrays for farm to plant and plant to center:\n",
    "if farm_to_plant_costs.shape[1] < 18:\n",
    "    missing_cols = 18 - farm_to_plant_costs.shape[1]\n",
    "    for i in range(missing_cols):\n",
    "        farms_data[f\"Plant_{farm_to_plant_costs.shape[1] + i + 1}\"] = farms_data.iloc[:, 5:5 + farm_to_plant_costs.shape[1]].mean(axis=1)\n",
    "    farm_to_plant_costs = farms_data.iloc[:, 5:5 + 18].values\n",
    "\n",
    "if plant_to_center_costs.shape[1] < len(center_ids):\n",
    "    missing_cols = len(center_ids) - plant_to_center_costs.shape[1]\n",
    "    for i in range(missing_cols):\n",
    "        processing_data[f\"Missing_Center_{i+1}\"] = processing_data.iloc[:, 5:5 + plant_to_center_costs.shape[1]].mean(axis=1)\n",
    "    plant_to_center_costs = processing_data.iloc[:, 5:5 + len(center_ids)].values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of farm_to_plant_costs: (249, 18)\n",
      "Number of plant_ids: 18\n",
      "Farm IDs: ['Farm_1', 'Farm_2', 'Farm_3', 'Farm_4', 'Farm_5', 'Farm_6', 'Farm_7', 'Farm_8', 'Farm_9', 'Farm_10', 'Farm_11', 'Farm_12', 'Farm_13', 'Farm_14', 'Farm_15', 'Farm_16', 'Farm_17', 'Farm_18', 'Farm_19', 'Farm_20', 'Farm_21', 'Farm_22', 'Farm_23', 'Farm_24', 'Farm_25', 'Farm_26', 'Farm_27', 'Farm_28', 'Farm_29', 'Farm_30', 'Farm_31', 'Farm_32', 'Farm_33', 'Farm_34', 'Farm_35', 'Farm_36', 'Farm_37', 'Farm_38', 'Farm_39', 'Farm_40', 'Farm_41', 'Farm_42', 'Farm_43', 'Farm_44', 'Farm_45', 'Farm_46', 'Farm_47', 'Farm_48', 'Farm_49', 'Farm_50', 'Farm_51', 'Farm_52', 'Farm_53', 'Farm_54', 'Farm_55', 'Farm_56', 'Farm_57', 'Farm_58', 'Farm_59', 'Farm_60', 'Farm_61', 'Farm_62', 'Farm_63', 'Farm_64', 'Farm_65', 'Farm_66', 'Farm_67', 'Farm_68', 'Farm_69', 'Farm_70', 'Farm_71', 'Farm_72', 'Farm_73', 'Farm_74', 'Farm_75', 'Farm_76', 'Farm_77', 'Farm_78', 'Farm_79', 'Farm_80', 'Farm_81', 'Farm_82', 'Farm_83', 'Farm_84', 'Farm_85', 'Farm_86', 'Farm_87', 'Farm_88', 'Farm_89', 'Farm_90', 'Farm_91', 'Farm_92', 'Farm_93', 'Farm_94', 'Farm_95', 'Farm_96', 'Farm_97', 'Farm_98', 'Farm_99', 'Farm_100', 'Farm_101', 'Farm_102', 'Farm_103', 'Farm_104', 'Farm_105', 'Farm_106', 'Farm_107', 'Farm_108', 'Farm_109', 'Farm_110', 'Farm_111', 'Farm_112', 'Farm_113', 'Farm_114', 'Farm_115', 'Farm_116', 'Farm_117', 'Farm_118', 'Farm_119', 'Farm_120', 'Farm_121', 'Farm_122', 'Farm_123', 'Farm_124', 'Farm_125', 'Farm_126', 'Farm_127', 'Farm_128', 'Farm_129', 'Farm_130', 'Farm_131', 'Farm_132', 'Farm_133', 'Farm_134', 'Farm_135', 'Farm_136', 'Farm_137', 'Farm_138', 'Farm_139', 'Farm_140', 'Farm_141', 'Farm_142', 'Farm_143', 'Farm_144', 'Farm_145', 'Farm_146', 'Farm_147', 'Farm_148', 'Farm_149', 'Farm_150', 'Farm_151', 'Farm_152', 'Farm_153', 'Farm_154', 'Farm_155', 'Farm_156', 'Farm_157', 'Farm_158', 'Farm_159', 'Farm_160', 'Farm_161', 'Farm_162', 'Farm_163', 'Farm_164', 'Farm_165', 'Farm_166', 'Farm_167', 'Farm_168', 'Farm_169', 'Farm_170', 'Farm_171', 'Farm_172', 'Farm_173', 'Farm_174', 'Farm_175', 'Farm_176', 'Farm_177', 'Farm_178', 'Farm_179', 'Farm_180', 'Farm_181', 'Farm_182', 'Farm_183', 'Farm_184', 'Farm_185', 'Farm_186', 'Farm_187', 'Farm_188', 'Farm_189', 'Farm_190', 'Farm_191', 'Farm_192', 'Farm_193', 'Farm_194', 'Farm_195', 'Farm_196', 'Farm_197', 'Farm_198', 'Farm_199', 'Farm_200', 'Farm_201', 'Farm_202', 'Farm_203', 'Farm_204', 'Farm_205', 'Farm_206', 'Farm_207', 'Farm_208', 'Farm_209', 'Farm_210', 'Farm_211', 'Farm_212', 'Farm_213', 'Farm_214', 'Farm_215', 'Farm_216', 'Farm_217', 'Farm_218', 'Farm_219', 'Farm_220', 'Farm_221', 'Farm_222', 'Farm_223', 'Farm_224', 'Farm_225', 'Farm_226', 'Farm_227', 'Farm_228', 'Farm_229', 'Farm_230', 'Farm_231', 'Farm_232', 'Farm_233', 'Farm_234', 'Farm_235', 'Farm_236', 'Farm_237', 'Farm_238', 'Farm_239', 'Farm_240', 'Farm_241', 'Farm_242', 'Farm_243', 'Farm_244', 'Farm_245', 'Farm_246', 'Farm_247', 'Farm_248', 'Farm_249']\n",
      "Plant IDs: ['Plant_1', 'Plant_2', 'Plant_3', 'Plant_4', 'Plant_5', 'Plant_6', 'Plant_7', 'Plant_8', 'Plant_9', 'Plant_10', 'Plant_11', 'Plant_12', 'Plant_13', 'Plant_14', 'Plant_15', 'Plant_16', 'Plant_17', 'Plant_18']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of farm_to_plant_costs: {farm_to_plant_costs.shape}\")\n",
    "print(f\"Number of plant_ids: {len(plant_ids)}\")\n",
    "print(f\"Farm IDs: {farm_ids}\")\n",
    "print(f\"Plant IDs: {plant_ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Set parameter LicenseID to value 2612728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic license - for non-commercial use only - expires 2026-01-21\n"
     ]
    }
   ],
   "source": [
    "# Create the optimization model\n",
    "model = Model(\"BioAgri_Solutions\")\n",
    "\n",
    "# Decision variables\n",
    "x_farm_to_plant = model.addVars(\n",
    "    farm_ids, plant_ids, name=\"x_farm_to_plant\", lb=0, vtype=GRB.CONTINUOUS)\n",
    "x_plant_to_center = model.addVars(\n",
    "    plant_ids, center_ids, name=\"x_plant_to_center\", lb=0, vtype=GRB.CONTINUOUS)\n",
    "\n",
    "# Objective: Minimize total cost\n",
    "model.setObjective(\n",
    "    quicksum(x_farm_to_plant[f, p] * farm_to_plant_costs[farm_ids.index(f), plant_ids.index(p)]\n",
    "             for f in farm_ids for p in plant_ids)\n",
    "    + quicksum(x_plant_to_center[p, c] * plant_to_center_costs[plant_ids.index(p), center_ids.index(c)]\n",
    "               for p in plant_ids for c in center_ids)\n",
    "    + quicksum(x_farm_to_plant[f, p] * processing_costs[p]\n",
    "               for f in farm_ids for p in plant_ids),\n",
    "    GRB.MINIMIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 12.0.0 build v12.0.0rc1 (win64 - Windows 11.0 (26100.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i7-9750H CPU @ 2.60GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 6 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Optimize a model with 387 rows, 6318 columns and 17118 nonzeros\n",
      "Model fingerprint: 0x7822a7dd\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [2e+00, 1e+01]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [6e+01, 3e+04]\n",
      "Presolve time: 0.03s\n",
      "Presolved: 387 rows, 6318 columns, 17118 nonzeros\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    0.0000000e+00   2.902000e+04   0.000000e+00      0s\n",
      "     418    2.2572950e+05   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 418 iterations and 0.06 seconds (0.02 work units)\n",
      "Optimal objective  2.257294998e+05\n"
     ]
    }
   ],
   "source": [
    "# Constraints\n",
    "# 1. Farm capacity\n",
    "model.addConstrs((quicksum(x_farm_to_plant[f, p] for p in plant_ids) <= farm_capacities[f]\n",
    "                  for f in farm_ids), name=\"Farm_Capacity\")\n",
    "\n",
    "# 2. Processing plant capacity\n",
    "model.addConstrs((quicksum(x_farm_to_plant[f, p] for f in farm_ids) <= processing_capacities[p]\n",
    "                  for p in plant_ids), name=\"Plant_Capacity\")\n",
    "\n",
    "# 3. Home center demand\n",
    "model.addConstrs((quicksum(x_plant_to_center[p, c] for p in plant_ids) >= center_demands[c]\n",
    "                  for c in center_ids), name=\"Center_Demand\")\n",
    "\n",
    "# 4. Flow conservation at processing plants\n",
    "model.addConstrs(\n",
    "    quicksum(x_farm_to_plant[f, p] for f in farm_ids) == quicksum(x_plant_to_center[p, c] for c in center_ids)\n",
    "    for p in plant_ids\n",
    ")\n",
    "\n",
    "# Solve the model\n",
    "model.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum Total Cost: 225729.49984810984\n",
      "Farm Farm_1 -> Plant Plant_2: 173.0 tons\n",
      "Farm Farm_3 -> Plant Plant_9: 516.0 tons\n",
      "Farm Farm_8 -> Plant Plant_9: 360.0 tons\n",
      "Farm Farm_13 -> Plant Plant_1: 562.0 tons\n",
      "Farm Farm_14 -> Plant Plant_2: 526.0 tons\n",
      "Farm Farm_18 -> Plant Plant_9: 525.0 tons\n",
      "Farm Farm_19 -> Plant Plant_9: 229.0 tons\n",
      "Farm Farm_20 -> Plant Plant_10: 558.0 tons\n",
      "Farm Farm_22 -> Plant Plant_10: 285.0 tons\n",
      "Farm Farm_25 -> Plant Plant_16: 512.0 tons\n",
      "Farm Farm_35 -> Plant Plant_10: 212.0 tons\n",
      "Farm Farm_36 -> Plant Plant_9: 519.0 tons\n",
      "Farm Farm_37 -> Plant Plant_2: 550.0 tons\n",
      "Farm Farm_38 -> Plant Plant_6: 379.0 tons\n",
      "Farm Farm_42 -> Plant Plant_9: 470.0 tons\n",
      "Farm Farm_51 -> Plant Plant_10: 422.0 tons\n",
      "Farm Farm_52 -> Plant Plant_1: 317.0 tons\n",
      "Farm Farm_53 -> Plant Plant_10: 391.0 tons\n",
      "Farm Farm_67 -> Plant Plant_9: 291.0 tons\n",
      "Farm Farm_75 -> Plant Plant_9: 277.0 tons\n",
      "Farm Farm_79 -> Plant Plant_10: 452.0 tons\n",
      "Farm Farm_80 -> Plant Plant_9: 212.0 tons\n",
      "Farm Farm_81 -> Plant Plant_2: 498.0 tons\n",
      "Farm Farm_82 -> Plant Plant_9: 275.0 tons\n",
      "Farm Farm_93 -> Plant Plant_10: 437.0 tons\n",
      "Farm Farm_98 -> Plant Plant_16: 267.0 tons\n",
      "Farm Farm_99 -> Plant Plant_1: 243.0 tons\n",
      "Farm Farm_100 -> Plant Plant_2: 260.0 tons\n",
      "Farm Farm_107 -> Plant Plant_9: 457.0 tons\n",
      "Farm Farm_110 -> Plant Plant_1: 481.0 tons\n",
      "Farm Farm_114 -> Plant Plant_9: 288.0 tons\n",
      "Farm Farm_115 -> Plant Plant_1: 345.0 tons\n",
      "Farm Farm_118 -> Plant Plant_9: 388.0 tons\n",
      "Farm Farm_122 -> Plant Plant_9: 395.0 tons\n",
      "Farm Farm_125 -> Plant Plant_10: 506.0 tons\n",
      "Farm Farm_129 -> Plant Plant_1: 313.0 tons\n",
      "Farm Farm_130 -> Plant Plant_10: 538.0 tons\n",
      "Farm Farm_133 -> Plant Plant_9: 337.0 tons\n",
      "Farm Farm_139 -> Plant Plant_9: 485.0 tons\n",
      "Farm Farm_144 -> Plant Plant_6: 410.0 tons\n",
      "Farm Farm_146 -> Plant Plant_2: 379.0 tons\n",
      "Farm Farm_152 -> Plant Plant_1: 495.0 tons\n",
      "Farm Farm_153 -> Plant Plant_10: 205.0 tons\n",
      "Farm Farm_159 -> Plant Plant_9: 524.0 tons\n",
      "Farm Farm_161 -> Plant Plant_6: 472.0 tons\n",
      "Farm Farm_165 -> Plant Plant_9: 448.0 tons\n",
      "Farm Farm_167 -> Plant Plant_2: 309.0 tons\n",
      "Farm Farm_168 -> Plant Plant_1: 212.0 tons\n",
      "Farm Farm_176 -> Plant Plant_1: 420.0 tons\n",
      "Farm Farm_181 -> Plant Plant_9: 245.0 tons\n",
      "Farm Farm_182 -> Plant Plant_9: 473.0 tons\n",
      "Farm Farm_185 -> Plant Plant_9: 548.0 tons\n",
      "Farm Farm_186 -> Plant Plant_6: 302.0 tons\n",
      "Farm Farm_187 -> Plant Plant_1: 323.0 tons\n",
      "Farm Farm_188 -> Plant Plant_9: 209.0 tons\n",
      "Farm Farm_194 -> Plant Plant_10: 448.0 tons\n",
      "Farm Farm_195 -> Plant Plant_10: 586.0 tons\n",
      "Farm Farm_203 -> Plant Plant_16: 519.0 tons\n",
      "Farm Farm_207 -> Plant Plant_10: 479.0 tons\n",
      "Farm Farm_208 -> Plant Plant_10: 354.0 tons\n",
      "Farm Farm_214 -> Plant Plant_10: 481.0 tons\n",
      "Farm Farm_216 -> Plant Plant_1: 575.0 tons\n",
      "Farm Farm_224 -> Plant Plant_6: 594.0 tons\n",
      "Farm Farm_225 -> Plant Plant_2: 273.0 tons\n",
      "Farm Farm_226 -> Plant Plant_1: 386.0 tons\n",
      "Farm Farm_228 -> Plant Plant_6: 536.0 tons\n",
      "Farm Farm_230 -> Plant Plant_9: 255.0 tons\n",
      "Farm Farm_233 -> Plant Plant_9: 439.0 tons\n",
      "Farm Farm_234 -> Plant Plant_1: 195.0 tons\n",
      "Farm Farm_236 -> Plant Plant_10: 464.0 tons\n",
      "Farm Farm_240 -> Plant Plant_16: 317.0 tons\n",
      "Farm Farm_242 -> Plant Plant_9: 404.0 tons\n",
      "Farm Farm_246 -> Plant Plant_16: 267.0 tons\n",
      "Farm Farm_248 -> Plant Plant_6: 223.0 tons\n",
      "Plant Plant_1 -> Center Center_6: 86.0 tons\n",
      "Plant Plant_1 -> Center Center_7: 480.0 tons\n",
      "Plant Plant_1 -> Center Center_9: 72.0 tons\n",
      "Plant Plant_1 -> Center Center_14: 258.0 tons\n",
      "Plant Plant_1 -> Center Center_17: 286.0 tons\n",
      "Plant Plant_1 -> Center Center_19: 455.0 tons\n",
      "Plant Plant_1 -> Center Center_20: 87.0 tons\n",
      "Plant Plant_1 -> Center Center_22: 255.0 tons\n",
      "Plant Plant_1 -> Center Center_39: 331.0 tons\n",
      "Plant Plant_1 -> Center Center_40: 150.0 tons\n",
      "Plant Plant_1 -> Center Center_48: 192.0 tons\n",
      "Plant Plant_1 -> Center Center_53: 260.0 tons\n",
      "Plant Plant_1 -> Center Center_57: 107.0 tons\n",
      "Plant Plant_1 -> Center Center_60: 437.0 tons\n",
      "Plant Plant_1 -> Center Center_69: 162.0 tons\n",
      "Plant Plant_1 -> Center Center_78: 130.0 tons\n",
      "Plant Plant_1 -> Center Center_80: 484.0 tons\n",
      "Plant Plant_1 -> Center Center_84: 443.0 tons\n",
      "Plant Plant_1 -> Center Center_89: 105.0 tons\n",
      "Plant Plant_1 -> Center Center_95: 87.0 tons\n",
      "Plant Plant_2 -> Center Center_11: 473.0 tons\n",
      "Plant Plant_2 -> Center Center_13: 138.0 tons\n",
      "Plant Plant_2 -> Center Center_35: 277.0 tons\n",
      "Plant Plant_2 -> Center Center_37: 245.0 tons\n",
      "Plant Plant_2 -> Center Center_54: 490.0 tons\n",
      "Plant Plant_2 -> Center Center_61: 315.0 tons\n",
      "Plant Plant_2 -> Center Center_73: 326.0 tons\n",
      "Plant Plant_2 -> Center Center_83: 362.0 tons\n",
      "Plant Plant_2 -> Center Center_85: 342.0 tons\n",
      "Plant Plant_6 -> Center Center_2: 348.0 tons\n",
      "Plant Plant_6 -> Center Center_23: 127.0 tons\n",
      "Plant Plant_6 -> Center Center_25: 377.0 tons\n",
      "Plant Plant_6 -> Center Center_31: 143.0 tons\n",
      "Plant Plant_6 -> Center Center_45: 132.0 tons\n",
      "Plant Plant_6 -> Center Center_58: 122.0 tons\n",
      "Plant Plant_6 -> Center Center_67: 368.0 tons\n",
      "Plant Plant_6 -> Center Center_74: 211.0 tons\n",
      "Plant Plant_6 -> Center Center_75: 292.0 tons\n",
      "Plant Plant_6 -> Center Center_79: 371.0 tons\n",
      "Plant Plant_6 -> Center Center_87: 425.0 tons\n",
      "Plant Plant_9 -> Center Center_1: 82.0 tons\n",
      "Plant Plant_9 -> Center Center_4: 161.0 tons\n",
      "Plant Plant_9 -> Center Center_5: 340.0 tons\n",
      "Plant Plant_9 -> Center Center_8: 149.0 tons\n",
      "Plant Plant_9 -> Center Center_10: 469.0 tons\n",
      "Plant Plant_9 -> Center Center_15: 320.0 tons\n",
      "Plant Plant_9 -> Center Center_18: 437.0 tons\n",
      "Plant Plant_9 -> Center Center_20: 171.0 tons\n",
      "Plant Plant_9 -> Center Center_21: 327.0 tons\n",
      "Plant Plant_9 -> Center Center_24: 450.0 tons\n",
      "Plant Plant_9 -> Center Center_26: 147.0 tons\n",
      "Plant Plant_9 -> Center Center_29: 399.0 tons\n",
      "Plant Plant_9 -> Center Center_30: 385.0 tons\n",
      "Plant Plant_9 -> Center Center_32: 129.0 tons\n",
      "Plant Plant_9 -> Center Center_38: 439.0 tons\n",
      "Plant Plant_9 -> Center Center_42: 124.0 tons\n",
      "Plant Plant_9 -> Center Center_44: 257.0 tons\n",
      "Plant Plant_9 -> Center Center_50: 410.0 tons\n",
      "Plant Plant_9 -> Center Center_51: 489.0 tons\n",
      "Plant Plant_9 -> Center Center_52: 336.0 tons\n",
      "Plant Plant_9 -> Center Center_55: 228.0 tons\n",
      "Plant Plant_9 -> Center Center_59: 264.0 tons\n",
      "Plant Plant_9 -> Center Center_64: 320.0 tons\n",
      "Plant Plant_9 -> Center Center_65: 403.0 tons\n",
      "Plant Plant_9 -> Center Center_68: 68.0 tons\n",
      "Plant Plant_9 -> Center Center_77: 195.0 tons\n",
      "Plant Plant_9 -> Center Center_81: 370.0 tons\n",
      "Plant Plant_9 -> Center Center_82: 92.0 tons\n",
      "Plant Plant_9 -> Center Center_86: 225.0 tons\n",
      "Plant Plant_9 -> Center Center_88: 118.0 tons\n",
      "Plant Plant_9 -> Center Center_91: 253.0 tons\n",
      "Plant Plant_9 -> Center Center_93: 464.0 tons\n",
      "Plant Plant_9 -> Center Center_99: 64.0 tons\n",
      "Plant Plant_9 -> Center Center_101: 126.0 tons\n",
      "Plant Plant_9 -> Center Center_102: 358.0 tons\n",
      "Plant Plant_10 -> Center Center_3: 464.0 tons\n",
      "Plant Plant_10 -> Center Center_12: 267.0 tons\n",
      "Plant Plant_10 -> Center Center_16: 470.0 tons\n",
      "Plant Plant_10 -> Center Center_27: 395.0 tons\n",
      "Plant Plant_10 -> Center Center_28: 414.0 tons\n",
      "Plant Plant_10 -> Center Center_33: 87.0 tons\n",
      "Plant Plant_10 -> Center Center_34: 457.0 tons\n",
      "Plant Plant_10 -> Center Center_36: 183.0 tons\n",
      "Plant Plant_10 -> Center Center_41: 474.0 tons\n",
      "Plant Plant_10 -> Center Center_43: 343.0 tons\n",
      "Plant Plant_10 -> Center Center_46: 476.0 tons\n",
      "Plant Plant_10 -> Center Center_47: 486.0 tons\n",
      "Plant Plant_10 -> Center Center_49: 105.0 tons\n",
      "Plant Plant_10 -> Center Center_63: 122.0 tons\n",
      "Plant Plant_10 -> Center Center_66: 283.0 tons\n",
      "Plant Plant_10 -> Center Center_72: 233.0 tons\n",
      "Plant Plant_10 -> Center Center_76: 194.0 tons\n",
      "Plant Plant_10 -> Center Center_90: 168.0 tons\n",
      "Plant Plant_10 -> Center Center_92: 469.0 tons\n",
      "Plant Plant_10 -> Center Center_97: 250.0 tons\n",
      "Plant Plant_10 -> Center Center_98: 285.0 tons\n",
      "Plant Plant_10 -> Center Center_100: 193.0 tons\n",
      "Plant Plant_16 -> Center Center_56: 457.0 tons\n",
      "Plant Plant_16 -> Center Center_62: 496.0 tons\n",
      "Plant Plant_16 -> Center Center_70: 112.0 tons\n",
      "Plant Plant_16 -> Center Center_71: 421.0 tons\n",
      "Plant Plant_16 -> Center Center_94: 104.0 tons\n",
      "Plant Plant_16 -> Center Center_96: 292.0 tons\n"
     ]
    }
   ],
   "source": [
    "# Output optimized decision variables and total cost\n",
    "if model.status == GRB.OPTIMAL:\n",
    "    print(f\"Minimum Total Cost: {model.objVal}\")\n",
    "    for f in farm_ids:\n",
    "        for p in plant_ids:\n",
    "            if x_farm_to_plant[f, p].x > 0:\n",
    "                print(f\"Farm {f} -> Plant {p}: {x_farm_to_plant[f, p].x} tons\")\n",
    "\n",
    "    for p in plant_ids:\n",
    "        for c in center_ids:\n",
    "            if x_plant_to_center[p, c].x > 0:\n",
    "                print(f\"Plant {p} -> Center {c}: {x_plant_to_center[p, c].x} tons\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading datasets again\n",
    "farms_data = pd.read_csv('https://raw.githubusercontent.com/selvinfurtado01/operational_reserach/refs/heads/main/farms.csv')\n",
    "processing_data = pd.read_csv('https://raw.githubusercontent.com/selvinfurtado01/operational_reserach/refs/heads/main/processing.csv')\n",
    "centers_data = pd.read_csv('https://raw.githubusercontent.com/selvinfurtado01/operational_reserach/refs/heads/main/centers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centers Dataset Columns: Index(['Center_ID', 'Requested_Demand_Tons', 'Region'], dtype='object')\n",
      "Farms Dataset Columns: Index(['Farm_ID', 'Bio_Material_Capacity_Tons', 'Quality', 'Cost_Per_Ton',\n",
      "       'Transport_Cost_To_Plant_1', 'Transport_Cost_To_Plant_2',\n",
      "       'Transport_Cost_To_Plant_3', 'Transport_Cost_To_Plant_4',\n",
      "       'Transport_Cost_To_Plant_5', 'Transport_Cost_To_Plant_6',\n",
      "       'Transport_Cost_To_Plant_7', 'Transport_Cost_To_Plant_8',\n",
      "       'Transport_Cost_To_Plant_9', 'Transport_Cost_To_Plant_10',\n",
      "       'Transport_Cost_To_Plant_11', 'Transport_Cost_To_Plant_12',\n",
      "       'Transport_Cost_To_Plant_13', 'Transport_Cost_To_Plant_14',\n",
      "       'Transport_Cost_To_Plant_15', 'Transport_Cost_To_Plant_16',\n",
      "       'Transport_Cost_To_Plant_17', 'Transport_Cost_To_Plant_18'],\n",
      "      dtype='object')\n",
      "Processing Dataset Columns: Index(['Processing_Plant_ID', 'Region', 'Capacity_Tons',\n",
      "       'Processing_Cost_Per_Ton', 'Transport_Cost_To_Center_1',\n",
      "       'Transport_Cost_To_Center_2', 'Transport_Cost_To_Center_3',\n",
      "       'Transport_Cost_To_Center_4', 'Transport_Cost_To_Center_5',\n",
      "       'Transport_Cost_To_Center_6',\n",
      "       ...\n",
      "       'Transport_Cost_To_Center_93', 'Transport_Cost_To_Center_94',\n",
      "       'Transport_Cost_To_Center_95', 'Transport_Cost_To_Center_96',\n",
      "       'Transport_Cost_To_Center_97', 'Transport_Cost_To_Center_98',\n",
      "       'Transport_Cost_To_Center_99', 'Transport_Cost_To_Center_100',\n",
      "       'Transport_Cost_To_Center_101', 'Transport_Cost_To_Center_102'],\n",
      "      dtype='object', length=106)\n"
     ]
    }
   ],
   "source": [
    "# Print column names to debug KeyError\n",
    "print(\"Centers Dataset Columns:\", centers_data.columns)\n",
    "print(\"Farms Dataset Columns:\", farms_data.columns)\n",
    "print(\"Processing Dataset Columns:\", processing_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure column names are stripped of extra spaces\n",
    "centers_data.columns = centers_data.columns.str.strip()\n",
    "farms_data.columns = farms_data.columns.str.strip()\n",
    "processing_data.columns = processing_data.columns.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure expected column names exist\n",
    "expected_processing_columns = [\"Processing_Plant_ID\", \"Region\", \"Capacity_Tons\", \"Processing_Cost_Per_Ton\"]\n",
    "expected_centers_columns = [\"Center_ID\", \"Requested_Demand_Tons\", \"Region\"]\n",
    "expected_farms_columns = [\"Farm_ID\", \"Bio_Material_Capacity_Tons\", \"Quality\", \"Cost_Per_Ton\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing columns\n",
    "missing_processing_cols = [col for col in expected_processing_columns if col not in processing_data.columns]\n",
    "missing_centers_cols = [col for col in expected_centers_columns if col not in centers_data.columns]\n",
    "missing_farms_cols = [col for col in expected_farms_columns if col not in farms_data.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing columns in processing_data: []\n",
      "Missing columns in centers_data: []\n",
      "Missing columns in farms_data: []\n"
     ]
    }
   ],
   "source": [
    "print(\"Missing columns in processing_data:\", missing_processing_cols)\n",
    "print(\"Missing columns in centers_data:\", missing_centers_cols)\n",
    "print(\"Missing columns in farms_data:\", missing_farms_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If all required columns exist, proceed with optimization\n",
    "if not missing_processing_cols and not missing_centers_cols and not missing_farms_cols:\n",
    "    # Extract unique regions for filtering\n",
    "    processing_regions = processing_data.set_index(\"Processing_Plant_ID\")[\"Region\"].to_dict()\n",
    "    center_regions = centers_data.set_index(\"Center_ID\")[\"Region\"].to_dict()\n",
    "\n",
    "    # Define the optimization problem\n",
    "    model = LpProblem(\"Optimal_Fertilizer_Distribution\", LpMinimize)\n",
    "\n",
    "    # Decision Variables\n",
    "    # Transport from farms to processing plants\n",
    "    farm_to_plant_vars = {\n",
    "        (farm, plant): LpVariable(f\"Transport_{farm}_{plant}\", lowBound=0)\n",
    "        for farm in farms_data[\"Farm_ID\"]\n",
    "        for plant in processing_data[\"Processing_Plant_ID\"]\n",
    "    }\n",
    "\n",
    "    # Transport from processing plants to home centers (WITH REGIONAL RESTRICTION)\n",
    "    plant_to_center_vars = {\n",
    "        (plant, center): LpVariable(f\"Transport_{plant}_{center}\", lowBound=0)\n",
    "        for plant in processing_data[\"Processing_Plant_ID\"]\n",
    "        for center in centers_data[\"Center_ID\"]\n",
    "        if processing_regions.get(plant) == center_regions.get(center)  # Apply regional restriction\n",
    "    }\n",
    "\n",
    "    # Objective Function: Minimize Total Cost\n",
    "    model += lpSum(\n",
    "        farm_to_plant_vars[farm, plant] * farms_data.loc[farms_data[\"Farm_ID\"] == farm, f\"Transport_Cost_To_{plant}\"].values[0]\n",
    "        + farms_data.loc[farms_data[\"Farm_ID\"] == farm, \"Cost_Per_Ton\"].values[0]\n",
    "        for farm, plant in farm_to_plant_vars\n",
    "    ) + lpSum(\n",
    "        plant_to_center_vars[plant, center] * processing_data.loc[processing_data[\"Processing_Plant_ID\"] == plant, f\"Transport_Cost_To_{center}\"].values[0]\n",
    "        + processing_data.loc[processing_data[\"Processing_Plant_ID\"] == plant, \"Processing_Cost_Per_Ton\"].values[0]\n",
    "        for plant, center in plant_to_center_vars\n",
    "    )\n",
    "\n",
    "    # Constraints\n",
    "\n",
    "    # Supply constraint: Farms cannot supply more than their capacity\n",
    "    for farm in farms_data[\"Farm_ID\"]:\n",
    "        model += lpSum(farm_to_plant_vars[farm, plant] for plant in processing_data[\"Processing_Plant_ID\"]) <= farms_data.loc[farms_data[\"Farm_ID\"] == farm, \"Bio_Material_Capacity_Tons\"].values[0]\n",
    "\n",
    "    # Processing Capacity Constraint: Plants cannot process more than capacity\n",
    "    for plant in processing_data[\"Processing_Plant_ID\"]:\n",
    "        model += lpSum(farm_to_plant_vars[farm, plant] for farm in farms_data[\"Farm_ID\"]) <= processing_data.loc[processing_data[\"Processing_Plant_ID\"] == plant, \"Capacity_Tons\"].values[0]\n",
    "\n",
    "    # Demand Constraint: Home centers must receive exactly their required demand\n",
    "    for center in centers_data[\"Center_ID\"]:\n",
    "        model += lpSum(plant_to_center_vars[plant, center] for plant in processing_data[\"Processing_Plant_ID\"] if (plant, center) in plant_to_center_vars) == centers_data.loc[centers_data[\"Center_ID\"] == center, \"Requested_Demand_Tons\"].values[0]\n",
    "\n",
    "    # Flow Constraint: Total input to a processing plant must match the total output from the plant\n",
    "    for plant in processing_data[\"Processing_Plant_ID\"]:\n",
    "        model += lpSum(farm_to_plant_vars[farm, plant] for farm in farms_data[\"Farm_ID\"]) == lpSum(plant_to_center_vars[plant, center] for center in centers_data[\"Center_ID\"] if (plant, center) in plant_to_center_vars)\n",
    "\n",
    "    # Solve the model\n",
    "    model.solve()\n",
    "\n",
    "    # Extract optimal cost\n",
    "    optimal_cost = model.objective.value()\n",
    "    optimal_cost\n",
    "else:\n",
    "    print(\"Error: Some required columns are missing. Please check dataset column names.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Cost of High Quality Materials: 360401.7033432539\n"
     ]
    }
   ],
   "source": [
    "# Ensure column names are stripped of extra spaces\n",
    "centers_data.columns = centers_data.columns.str.strip()\n",
    "farms_data.columns = farms_data.columns.str.strip()\n",
    "processing_data.columns = processing_data.columns.str.strip()\n",
    "\n",
    "# Filter farms to include only those with quality levels 3 and 4\n",
    "high_quality_farms = farms_data[farms_data[\"Quality\"].isin([3, 4])]\n",
    "\n",
    "# Define the optimization problem with high-quality raw material sourcing\n",
    "model = LpProblem(\"Optimal_Fertilizer_Cost_High_Quality\", LpMinimize)\n",
    "\n",
    "# Decision Variables\n",
    "farm_to_plant_vars = {\n",
    "    (farm, plant): LpVariable(f\"Transport_{farm}_{plant}\", lowBound=0)\n",
    "    for farm in high_quality_farms[\"Farm_ID\"]\n",
    "    for plant in processing_data[\"Processing_Plant_ID\"]\n",
    "}\n",
    "\n",
    "plant_to_center_vars = {\n",
    "    (plant, center): LpVariable(f\"Transport_{plant}_{center}\", lowBound=0)\n",
    "    for plant in processing_data[\"Processing_Plant_ID\"]\n",
    "    for center in centers_data[\"Center_ID\"]\n",
    "}\n",
    "\n",
    "# Objective Function: Minimize Total Cost\n",
    "model += lpSum(\n",
    "    farm_to_plant_vars[farm, plant] * high_quality_farms.loc[high_quality_farms[\"Farm_ID\"] == farm, f\"Transport_Cost_To_{plant}\"].values[0]\n",
    "    + high_quality_farms.loc[high_quality_farms[\"Farm_ID\"] == farm, \"Cost_Per_Ton\"].values[0]\n",
    "    for farm, plant in farm_to_plant_vars\n",
    ") + lpSum(\n",
    "    plant_to_center_vars[plant, center] * processing_data.loc[processing_data[\"Processing_Plant_ID\"] == plant, f\"Transport_Cost_To_{center}\"].values[0]\n",
    "    + processing_data.loc[processing_data[\"Processing_Plant_ID\"] == plant, \"Processing_Cost_Per_Ton\"].values[0]\n",
    "    for plant, center in plant_to_center_vars\n",
    ")\n",
    "\n",
    "# Constraints\n",
    "\n",
    "# Supply constraint: Farms cannot supply more than their capacity\n",
    "for farm in high_quality_farms[\"Farm_ID\"]:\n",
    "    model += lpSum(farm_to_plant_vars[farm, plant] for plant in processing_data[\"Processing_Plant_ID\"]) <= high_quality_farms.loc[high_quality_farms[\"Farm_ID\"] == farm, \"Bio_Material_Capacity_Tons\"].values[0]\n",
    "\n",
    "# Processing Capacity Constraint: Plants cannot process more than capacity\n",
    "for plant in processing_data[\"Processing_Plant_ID\"]:\n",
    "    model += lpSum(farm_to_plant_vars[farm, plant] for farm in high_quality_farms[\"Farm_ID\"]) <= processing_data.loc[processing_data[\"Processing_Plant_ID\"] == plant, \"Capacity_Tons\"].values[0]\n",
    "\n",
    "# Demand Constraint: Home centers must receive exactly their required demand\n",
    "for center in centers_data[\"Center_ID\"]:\n",
    "    model += lpSum(plant_to_center_vars[plant, center] for plant in processing_data[\"Processing_Plant_ID\"]) == centers_data.loc[centers_data[\"Center_ID\"] == center, \"Requested_Demand_Tons\"].values[0]\n",
    "\n",
    "# Flow Constraint: Total input to a processing plant must match the total output from the plant\n",
    "for plant in processing_data[\"Processing_Plant_ID\"]:\n",
    "    model += lpSum(farm_to_plant_vars[farm, plant] for farm in high_quality_farms[\"Farm_ID\"]) == lpSum(plant_to_center_vars[plant, center] for center in centers_data[\"Center_ID\"])\n",
    "\n",
    "# Solve the model\n",
    "model.solve()\n",
    "\n",
    "# Extract optimal cost when using only high-quality raw materials\n",
    "optimal_cost_high_quality = model.objective.value()\n",
    "print(f\"Optimal Cost of High Quality Materials: {optimal_cost_high_quality}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Cost of Risk Mitigation: 670462.8714653344\n"
     ]
    }
   ],
   "source": [
    "# Total raw material sourced from farms\n",
    "total_raw_material = farms_data[\"Bio_Material_Capacity_Tons\"].sum()\n",
    "\n",
    "# Define the optimization problem with new constraints\n",
    "model = LpProblem(\"Optimal_Fertilizer_Distribution_With_Risk_Mitigation\", LpMinimize)\n",
    "\n",
    "# Decision Variables\n",
    "# Transport from farms to processing plants\n",
    "farm_to_plant_vars = {\n",
    "    (farm, plant): LpVariable(f\"Transport_{farm}_{plant}\", lowBound=0)\n",
    "    for farm in farms_data[\"Farm_ID\"]\n",
    "    for plant in processing_data[\"Processing_Plant_ID\"]\n",
    "}\n",
    "\n",
    "# Transport from processing plants to home centers\n",
    "plant_to_center_vars = {\n",
    "    (plant, center): LpVariable(f\"Transport_{plant}_{center}\", lowBound=0)\n",
    "    for plant in processing_data[\"Processing_Plant_ID\"]\n",
    "    for center in centers_data[\"Center_ID\"]\n",
    "}\n",
    "\n",
    "# Objective Function: Minimize Total Cost\n",
    "model += lpSum(\n",
    "    farm_to_plant_vars[farm, plant] * farms_data.loc[farms_data[\"Farm_ID\"] == farm, f\"Transport_Cost_To_{plant}\"].values[0]\n",
    "    + farms_data.loc[farms_data[\"Farm_ID\"] == farm, \"Cost_Per_Ton\"].values[0]\n",
    "    for farm, plant in farm_to_plant_vars\n",
    ") + lpSum(\n",
    "    plant_to_center_vars[plant, center] * processing_data.loc[processing_data[\"Processing_Plant_ID\"] == plant, f\"Transport_Cost_To_{center}\"].values[0]\n",
    "    + processing_data.loc[processing_data[\"Processing_Plant_ID\"] == plant, \"Processing_Cost_Per_Ton\"].values[0]\n",
    "    for plant, center in plant_to_center_vars\n",
    ")\n",
    "\n",
    "# Constraints\n",
    "\n",
    "# Supply constraint: Farms cannot supply more than their capacity\n",
    "for farm in farms_data[\"Farm_ID\"]:\n",
    "    model += lpSum(farm_to_plant_vars[farm, plant] for plant in processing_data[\"Processing_Plant_ID\"]) <= farms_data.loc[farms_data[\"Farm_ID\"] == farm, \"Bio_Material_Capacity_Tons\"].values[0]\n",
    "\n",
    "# Processing Capacity Constraint: Plants cannot process more than capacity and no more than 3% of all raw material\n",
    "for plant in processing_data[\"Processing_Plant_ID\"]:\n",
    "    model += lpSum(farm_to_plant_vars[farm, plant] for farm in farms_data[\"Farm_ID\"]) <= min(\n",
    "        processing_data.loc[processing_data[\"Processing_Plant_ID\"] == plant, \"Capacity_Tons\"].values[0],\n",
    "        0.03 * total_raw_material  # 3% sourcing risk mitigation\n",
    "    )\n",
    "\n",
    "# Demand Constraint: Home centers must receive exactly their required demand\n",
    "for center in centers_data[\"Center_ID\"]:\n",
    "    model += lpSum(plant_to_center_vars[plant, center] for plant in processing_data[\"Processing_Plant_ID\"]) == centers_data.loc[centers_data[\"Center_ID\"] == center, \"Requested_Demand_Tons\"].values[0]\n",
    "\n",
    "# Supply risk mitigation: A single plant cannot supply more than 50% of a home center's demand\n",
    "for center in centers_data[\"Center_ID\"]:\n",
    "    demand = centers_data.loc[centers_data[\"Center_ID\"] == center, \"Requested_Demand_Tons\"].values[0]\n",
    "    for plant in processing_data[\"Processing_Plant_ID\"]:\n",
    "        model += plant_to_center_vars[plant, center] <= 0.5 * demand\n",
    "\n",
    "# Flow Constraint: Total input to a processing plant must match the total output from the plant\n",
    "for plant in processing_data[\"Processing_Plant_ID\"]:\n",
    "    model += lpSum(farm_to_plant_vars[farm, plant] for farm in farms_data[\"Farm_ID\"]) == lpSum(plant_to_center_vars[plant, center] for center in centers_data[\"Center_ID\"])\n",
    "\n",
    "# Solve the model\n",
    "model.solve()\n",
    "\n",
    "# Extract optimal cost\n",
    "optimal_cost_risk_mitigation = model.objective.value()\n",
    "\n",
    "print(f\"Optimal Cost of Risk Mitigation: {optimal_cost_risk_mitigation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Cost with All Constraints: 366841.0160312151\n"
     ]
    }
   ],
   "source": [
    "from pulp import LpProblem, LpMinimize, LpVariable, lpSum\n",
    "\n",
    "# Ensure column names are stripped of extra spaces\n",
    "centers_data.columns = centers_data.columns.str.strip()\n",
    "farms_data.columns = farms_data.columns.str.strip()\n",
    "processing_data.columns = processing_data.columns.str.strip()\n",
    "\n",
    "# Total raw material sourced from farms\n",
    "total_raw_material = farms_data[\"Bio_Material_Capacity_Tons\"].sum()\n",
    "\n",
    "# Extract unique regions for filtering (Regional Restriction from part c)\n",
    "processing_regions = processing_data.set_index(\"Processing_Plant_ID\")[\"Region\"].to_dict()\n",
    "center_regions = centers_data.set_index(\"Center_ID\")[\"Region\"].to_dict()\n",
    "\n",
    "# Filter farms to include only those with quality levels 3 and 4 (High-Quality from part d)\n",
    "high_quality_farms = farms_data[farms_data[\"Quality\"].isin([3, 4])]\n",
    "\n",
    "# Define the optimization problem\n",
    "model = LpProblem(\"Optimal_Fertilizer_Distribution_All_Constraints\", LpMinimize)\n",
    "\n",
    "# Decision Variables\n",
    "# Transport from farms to processing plants\n",
    "farm_to_plant_vars = {\n",
    "    (farm, plant): LpVariable(f\"Transport_{farm}_{plant}\", lowBound=0)\n",
    "    for farm in high_quality_farms[\"Farm_ID\"]  # Only high-quality farms\n",
    "    for plant in processing_data[\"Processing_Plant_ID\"]\n",
    "}\n",
    "\n",
    "# Transport from processing plants to home centers with regional restriction\n",
    "plant_to_center_vars = {\n",
    "    (plant, center): LpVariable(f\"Transport_{plant}_{center}\", lowBound=0)\n",
    "    for plant in processing_data[\"Processing_Plant_ID\"]\n",
    "    for center in centers_data[\"Center_ID\"]\n",
    "    if processing_regions.get(plant) == center_regions.get(center)  # Regional Restriction\n",
    "}\n",
    "\n",
    "# Objective Function: Minimize Total Cost\n",
    "model += lpSum(\n",
    "    farm_to_plant_vars[farm, plant] * high_quality_farms.loc[high_quality_farms[\"Farm_ID\"] == farm, f\"Transport_Cost_To_{plant}\"].values[0]\n",
    "    + high_quality_farms.loc[high_quality_farms[\"Farm_ID\"] == farm, \"Cost_Per_Ton\"].values[0]\n",
    "    for farm, plant in farm_to_plant_vars\n",
    ") + lpSum(\n",
    "    plant_to_center_vars[plant, center] * processing_data.loc[processing_data[\"Processing_Plant_ID\"] == plant, f\"Transport_Cost_To_{center}\"].values[0]\n",
    "    + processing_data.loc[processing_data[\"Processing_Plant_ID\"] == plant, \"Processing_Cost_Per_Ton\"].values[0]\n",
    "    for plant, center in plant_to_center_vars\n",
    ")\n",
    "\n",
    "# Constraints\n",
    "\n",
    "# 1. Supply Constraint: Farms cannot supply more than their capacity\n",
    "for farm in high_quality_farms[\"Farm_ID\"]:\n",
    "    model += lpSum(farm_to_plant_vars[farm, plant] for plant in processing_data[\"Processing_Plant_ID\"]) <= high_quality_farms.loc[high_quality_farms[\"Farm_ID\"] == farm, \"Bio_Material_Capacity_Tons\"].values[0]\n",
    "\n",
    "# 2. Processing Capacity Constraint: Plants cannot process more than capacity or 3% of total raw material\n",
    "for plant in processing_data[\"Processing_Plant_ID\"]:\n",
    "    model += lpSum(farm_to_plant_vars[farm, plant] for farm in high_quality_farms[\"Farm_ID\"]) <= min(\n",
    "        processing_data.loc[processing_data[\"Processing_Plant_ID\"] == plant, \"Capacity_Tons\"].values[0],\n",
    "        0.03 * total_raw_material  # 3% sourcing risk mitigation\n",
    "    )\n",
    "\n",
    "# 3. Demand Constraint: Home centers must receive exactly their required demand\n",
    "for center in centers_data[\"Center_ID\"]:\n",
    "    model += lpSum(plant_to_center_vars[plant, center] for plant in processing_data[\"Processing_Plant_ID\"] if (plant, center) in plant_to_center_vars) == centers_data.loc[centers_data[\"Center_ID\"] == center, \"Requested_Demand_Tons\"].values[0]\n",
    "\n",
    "# 4. Supply Risk Mitigation: A single plant cannot supply more than 50% of a home center's demand\n",
    "for center in centers_data[\"Center_ID\"]:\n",
    "    demand = centers_data.loc[centers_data[\"Center_ID\"] == center, \"Requested_Demand_Tons\"].values[0]\n",
    "    for plant in processing_data[\"Processing_Plant_ID\"]:\n",
    "        if (plant, center) in plant_to_center_vars:\n",
    "            model += plant_to_center_vars[plant, center] <= 0.5 * demand\n",
    "\n",
    "# 5. Flow Constraint: Total input to a processing plant must match the total output from the plant\n",
    "for plant in processing_data[\"Processing_Plant_ID\"]:\n",
    "    model += lpSum(farm_to_plant_vars[farm, plant] for farm in high_quality_farms[\"Farm_ID\"]) == lpSum(\n",
    "        plant_to_center_vars[plant, center] for center in centers_data[\"Center_ID\"] if (plant, center) in plant_to_center_vars\n",
    "    )\n",
    "\n",
    "# Solve the model\n",
    "model.solve()\n",
    "\n",
    "# Extract the optimal cost\n",
    "optimal_cost_all_constraints = model.objective.value()\n",
    "print(f\"Optimal Cost with All Constraints: {optimal_cost_all_constraints}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model becomes infeasible at sourcing risk mitigation percentage: 2.4%\n"
     ]
    }
   ],
   "source": [
    "from pulp import LpStatus\n",
    "\n",
    "# Define a function to test feasibility with varying sourcing risk mitigation percentages\n",
    "def test_risk_mitigation_threshold():\n",
    "    # Initialize variables\n",
    "    step = 0.1  # Step to reduce the sourcing percentage (0.1% at a time)\n",
    "    sourcing_risk_percentage = 3.0  # Start with 3%\n",
    "    infeasible = False\n",
    "\n",
    "    # Iterate while the model remains feasible\n",
    "    while sourcing_risk_percentage > 0:\n",
    "        # Define the optimization problem\n",
    "        model = LpProblem(f\"Risk_Mitigation_{sourcing_risk_percentage:.1f}_Percent\", LpMinimize)\n",
    "\n",
    "        # Decision Variables\n",
    "        farm_to_plant_vars = {\n",
    "            (farm, plant): LpVariable(f\"Transport_{farm}_{plant}\", lowBound=0)\n",
    "            for farm in high_quality_farms[\"Farm_ID\"]  # High-quality farms\n",
    "            for plant in processing_data[\"Processing_Plant_ID\"]\n",
    "        }\n",
    "\n",
    "        plant_to_center_vars = {\n",
    "            (plant, center): LpVariable(f\"Transport_{plant}_{center}\", lowBound=0)\n",
    "            for plant in processing_data[\"Processing_Plant_ID\"]\n",
    "            for center in centers_data[\"Center_ID\"]\n",
    "            if processing_regions.get(plant) == center_regions.get(center)  # Regional restriction\n",
    "        }\n",
    "\n",
    "        # Objective Function: Minimize Total Cost\n",
    "        model += lpSum(\n",
    "            farm_to_plant_vars[farm, plant] * high_quality_farms.loc[high_quality_farms[\"Farm_ID\"] == farm, f\"Transport_Cost_To_{plant}\"].values[0]\n",
    "            + high_quality_farms.loc[high_quality_farms[\"Farm_ID\"] == farm, \"Cost_Per_Ton\"].values[0]\n",
    "            for farm, plant in farm_to_plant_vars\n",
    "        ) + lpSum(\n",
    "            plant_to_center_vars[plant, center] * processing_data.loc[processing_data[\"Processing_Plant_ID\"] == plant, f\"Transport_Cost_To_{center}\"].values[0]\n",
    "            + processing_data.loc[processing_data[\"Processing_Plant_ID\"] == plant, \"Processing_Cost_Per_Ton\"].values[0]\n",
    "            for plant, center in plant_to_center_vars\n",
    "        )\n",
    "\n",
    "        # Constraints\n",
    "\n",
    "        # 1. Supply Constraint\n",
    "        for farm in high_quality_farms[\"Farm_ID\"]:\n",
    "            model += lpSum(farm_to_plant_vars[farm, plant] for plant in processing_data[\"Processing_Plant_ID\"]) <= high_quality_farms.loc[high_quality_farms[\"Farm_ID\"] == farm, \"Bio_Material_Capacity_Tons\"].values[0]\n",
    "\n",
    "        # 2. Processing Capacity Constraint\n",
    "        for plant in processing_data[\"Processing_Plant_ID\"]:\n",
    "            model += lpSum(farm_to_plant_vars[farm, plant] for farm in high_quality_farms[\"Farm_ID\"]) <= min(\n",
    "                processing_data.loc[processing_data[\"Processing_Plant_ID\"] == plant, \"Capacity_Tons\"].values[0],\n",
    "                (sourcing_risk_percentage / 100) * total_raw_material  # Adjusted sourcing risk mitigation\n",
    "            )\n",
    "\n",
    "        # 3. Demand Constraint\n",
    "        for center in centers_data[\"Center_ID\"]:\n",
    "            model += lpSum(plant_to_center_vars[plant, center] for plant in processing_data[\"Processing_Plant_ID\"] if (plant, center) in plant_to_center_vars) == centers_data.loc[centers_data[\"Center_ID\"] == center, \"Requested_Demand_Tons\"].values[0]\n",
    "\n",
    "        # 4. Supply Risk Mitigation Constraint\n",
    "        for center in centers_data[\"Center_ID\"]:\n",
    "            demand = centers_data.loc[centers_data[\"Center_ID\"] == center, \"Requested_Demand_Tons\"].values[0]\n",
    "            for plant in processing_data[\"Processing_Plant_ID\"]:\n",
    "                if (plant, center) in plant_to_center_vars:\n",
    "                    model += plant_to_center_vars[plant, center] <= 0.5 * demand\n",
    "\n",
    "        # 5. Flow Constraint\n",
    "        for plant in processing_data[\"Processing_Plant_ID\"]:\n",
    "            model += lpSum(farm_to_plant_vars[farm, plant] for farm in high_quality_farms[\"Farm_ID\"]) == lpSum(\n",
    "                plant_to_center_vars[plant, center] for center in centers_data[\"Center_ID\"] if (plant, center) in plant_to_center_vars\n",
    "            )\n",
    "\n",
    "        # Solve the model\n",
    "        model.solve()\n",
    "\n",
    "        # Check feasibility\n",
    "        if LpStatus[model.status] != \"Optimal\":\n",
    "            infeasible = True\n",
    "            print(f\"Model becomes infeasible at sourcing risk mitigation percentage: {sourcing_risk_percentage:.1f}%\")\n",
    "            break\n",
    "\n",
    "        # Reduce the sourcing risk percentage\n",
    "        sourcing_risk_percentage -= step\n",
    "\n",
    "    # If the model remains feasible down to 0%\n",
    "    if not infeasible:\n",
    "        print(\"Model remains feasible even with 0% sourcing risk mitigation.\")\n",
    "\n",
    "# Run the function to find the infeasibility threshold\n",
    "test_risk_mitigation_threshold()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure column names are stripped of extra spaces\n",
    "centers_data.columns = centers_data.columns.str.strip()\n",
    "farms_data.columns = farms_data.columns.str.strip()\n",
    "processing_data.columns = processing_data.columns.str.strip()\n",
    "\n",
    "# Total raw material sourced from farms\n",
    "total_raw_material = farms_data[\"Bio_Material_Capacity_Tons\"].sum()\n",
    "\n",
    "# Find the lowest feasible sourcing risk percentage\n",
    "sourcing_risk_percentages = [2.9, 2.8, 2.7, 2.6, 2.5, 2.4, 2.3, 2.2, 2.1, 2.0, 1.9, 1.8, 1.7, 1.6, 1.5]  # Decreasing in steps of 0.1%\n",
    "infeasible_threshold = None\n",
    "\n",
    "for percent in sourcing_risk_percentages:\n",
    "    # Define the optimization problem with decreasing sourcing risk mitigation percentage\n",
    "    model = LpProblem(\"Sourcing_Risk_Limit_Test\", LpMinimize)\n",
    "\n",
    "    # Decision Variables\n",
    "    farm_to_plant_vars = {\n",
    "        (farm, plant): LpVariable(f\"Transport_{farm}_{plant}\", lowBound=0)\n",
    "        for farm in farms_data[\"Farm_ID\"]\n",
    "        for plant in processing_data[\"Processing_Plant_ID\"]\n",
    "    }\n",
    "\n",
    "    plant_to_center_vars = {\n",
    "        (plant, center): LpVariable(f\"Transport_{plant}_{center}\", lowBound=0)\n",
    "        for plant in processing_data[\"Processing_Plant_ID\"]\n",
    "        for center in centers_data[\"Center_ID\"]\n",
    "    }\n",
    "\n",
    "    # Objective Function: Minimize Total Cost\n",
    "    model += lpSum(\n",
    "        farm_to_plant_vars[farm, plant] * farms_data.loc[farms_data[\"Farm_ID\"] == farm, f\"Transport_Cost_To_{plant}\"].values[0]\n",
    "        + farms_data.loc[farms_data[\"Farm_ID\"] == farm, \"Cost_Per_Ton\"].values[0]\n",
    "        for farm, plant in farm_to_plant_vars\n",
    "    ) + lpSum(\n",
    "        plant_to_center_vars[plant, center] * processing_data.loc[processing_data[\"Processing_Plant_ID\"] == plant, f\"Transport_Cost_To_{center}\"].values[0]\n",
    "        + processing_data.loc[processing_data[\"Processing_Plant_ID\"] == plant, \"Processing_Cost_Per_Ton\"].values[0]\n",
    "        for plant, center in plant_to_center_vars\n",
    "    )\n",
    "\n",
    "    # Constraints\n",
    "\n",
    "    # Supply constraint: Farms cannot supply more than their capacity\n",
    "    for farm in farms_data[\"Farm_ID\"]:\n",
    "        model += lpSum(farm_to_plant_vars[farm, plant] for plant in processing_data[\"Processing_Plant_ID\"]) <= farms_data.loc[farms_data[\"Farm_ID\"] == farm, \"Bio_Material_Capacity_Tons\"].values[0]\n",
    "\n",
    "    # Processing Capacity Constraint: Plants cannot process more than capacity and no more than 'percent' of total raw material\n",
    "    for plant in processing_data[\"Processing_Plant_ID\"]:\n",
    "        model += lpSum(farm_to_plant_vars[farm, plant] for farm in farms_data[\"Farm_ID\"]) <= min(\n",
    "            processing_data.loc[processing_data[\"Processing_Plant_ID\"] == plant, \"Capacity_Tons\"].values[0],\n",
    "            (percent / 100) * total_raw_material  # Decreasing sourcing risk mitigation\n",
    "        )\n",
    "\n",
    "    # Demand Constraint: Home centers must receive exactly their required demand\n",
    "    for center in centers_data[\"Center_ID\"]:\n",
    "        model += lpSum(plant_to_center_vars[plant, center] for plant in processing_data[\"Processing_Plant_ID\"]) == centers_data.loc[centers_data[\"Center_ID\"] == center, \"Requested_Demand_Tons\"].values[0]\n",
    "\n",
    "    # Supply risk mitigation: A single plant cannot supply more than 50% of a home center's demand\n",
    "    for center in centers_data[\"Center_ID\"]:\n",
    "        demand = centers_data.loc[centers_data[\"Center_ID\"] == center, \"Requested_Demand_Tons\"].values[0]\n",
    "        for plant in processing_data[\"Processing_Plant_ID\"]:\n",
    "            model += plant_to_center_vars[plant, center] <= 0.5 * demand\n",
    "\n",
    "    # Flow Constraint: Total input to a processing plant must match the total output from the plant\n",
    "    for plant in processing_data[\"Processing_Plant_ID\"]:\n",
    "        model += lpSum(farm_to_plant_vars[farm, plant] for farm in farms_data[\"Farm_ID\"]) == lpSum(plant_to_center_vars[plant, center] for center in centers_data[\"Center_ID\"])\n",
    "\n",
    "    # Solve the model\n",
    "    model.solve()\n",
    "\n",
    "    # Check feasibility\n",
    "    if LpStatus[model.status] == \"Infeasible\":\n",
    "        infeasible_threshold = percent\n",
    "        break  # Stop when first infeasible percentage is found\n",
    "\n",
    "infeasible_threshold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/selvinfurtado01/operational_reserach/refs/heads/main/updated_gym_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gurobipy import Model, GRB\n",
    "\n",
    "# Initialize the optimization model\n",
    "model = Model(\"Optimal_Hypertrophy\")\n",
    "\n",
    "# Extract necessary data from the dataset\n",
    "exercises = df.index.tolist()  # Exercise indices (0 to 2636)\n",
    "hypertrophy = df[\"Hypertrophy Rating\"].tolist()  # Hypertrophy ratings\n",
    "sfr = df[\"Stimulus-to-Fatigue\"].tolist()  # SFR values\n",
    "body_part = df[\"BodyPart\"].tolist()  # Target muscle groups\n",
    "difficulty = df[\"Difficulty\"].tolist()  # Exercise difficulty levels\n",
    "category = df[\"Category\"].tolist()  # Training category (Powerlifting, Strongman, etc.)\n",
    "equipment = df[\"Equipment\"].fillna(\"Other\").tolist()  # Fill missing equipment values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gurobi.Constr *Awaiting Model Update*>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define decision variables (exercise proportions)\n",
    "x = model.addVars(exercises, lb=0, ub=0.05, vtype=GRB.CONTINUOUS, name=\"x\")\n",
    "\n",
    "# Objective Function: Maximize Hypertrophy Rating\n",
    "model.setObjective(sum(hypertrophy[i] * x[i] for i in exercises), GRB.MAXIMIZE)\n",
    "\n",
    "# Constraint 1: Total Allocation Must Sum to 1 (100% of the program)\n",
    "model.addConstr(sum(x[i] for i in exercises) == 1, \"Total_Allocation\")\n",
    "\n",
    "# Constraint 2: Body Part Allocation Constraints\n",
    "body_part_constraints = {\n",
    "    \"Traps\": 0.005, \"Neck\": 0.005, \"Forearms\": 0.005, \"Abdominals\": 0.04\n",
    "}\n",
    "\n",
    "# Ensure each required body part gets at least its minimum allocation\n",
    "for part, min_alloc in body_part_constraints.items():\n",
    "    model.addConstr(sum(x[i] for i in exercises if body_part[i] == part) >= min_alloc, f\"Min_{part}\")\n",
    "\n",
    "# General muscle groups should be at least 2.5%\n",
    "muscle_groups = set(body_part) - set(body_part_constraints.keys())\n",
    "for group in muscle_groups:\n",
    "    model.addConstr(sum(x[i] for i in exercises if body_part[i] == group) >= 0.025, f\"Min_{group}\")\n",
    "\n",
    "# Constraint 3: Leg Muscles Receive 2.6 Upper Body Allocation\n",
    "leg_muscles = [\"Adductors\", \"Abductors\", \"Calves\", \"Glutes\", \"Hamstrings\", \"Quadriceps\"]\n",
    "upper_body_muscles = [\"Biceps\", \"Triceps\", \"Chest\", \"Upper Back\", \"Lower Back\", \"Lats\"]\n",
    "\n",
    "leg_alloc = sum(x[i] for i in exercises if body_part[i] in leg_muscles)\n",
    "upper_body_alloc = sum(x[i] for i in exercises if body_part[i] in upper_body_muscles)\n",
    "model.addConstr(leg_alloc >= 2.6 * upper_body_alloc, \"Leg_vs_UpperBody\")\n",
    "\n",
    "# Constraint 4: Biceps = Triceps & Chest = Back\n",
    "biceps_alloc = sum(x[i] for i in exercises if body_part[i] == \"Biceps\")\n",
    "triceps_alloc = sum(x[i] for i in exercises if body_part[i] == \"Triceps\")\n",
    "model.addConstr(biceps_alloc == triceps_alloc, \"Biceps_Equal_Triceps\")\n",
    "\n",
    "chest_alloc = sum(x[i] for i in exercises if body_part[i] == \"Chest\")\n",
    "back_alloc = sum(x[i] for i in exercises if body_part[i] in [\"Upper Back\", \"Lower Back\", \"Lats\"])\n",
    "model.addConstr(chest_alloc == back_alloc, \"Chest_Equal_Back\")\n",
    "\n",
    "# Constraint 5: Overall Stimulus-to-Fatigue Ratio  0.55\n",
    "model.addConstr(sum(sfr[i] * x[i] for i in exercises) <= 0.55, \"SFR_Limit\")\n",
    "\n",
    "# Constraint 6: Beginner  1.4 Intermediate, Intermediate  1.1 Advanced\n",
    "beginner_alloc = sum(x[i] for i in exercises if difficulty[i] == \"Beginner\")\n",
    "intermediate_alloc = sum(x[i] for i in exercises if difficulty[i] == \"Intermediate\")\n",
    "advanced_alloc = sum(x[i] for i in exercises if difficulty[i] == \"Advanced\")\n",
    "\n",
    "model.addConstr(beginner_alloc >= 1.4 * intermediate_alloc, \"Beginner_vs_Intermediate\")\n",
    "model.addConstr(intermediate_alloc >= 1.1 * advanced_alloc, \"Intermediate_vs_Advanced\")\n",
    "\n",
    "# Constraint 7: Training Style Allocations\n",
    "strongman_alloc = sum(x[i] for i in exercises if category[i] == \"Strongman\")\n",
    "powerlifting_alloc = sum(x[i] for i in exercises if category[i] == \"Powerlifting\")\n",
    "olympic_alloc = sum(x[i] for i in exercises if category[i] == \"Olympic Weightlifting\")\n",
    "\n",
    "model.addConstr(strongman_alloc <= 0.08, \"Strongman_Limit\")\n",
    "model.addConstr(powerlifting_alloc >= 0.09, \"Powerlifting_Min\")\n",
    "model.addConstr(olympic_alloc >= 0.10, \"Olympic_Min\")\n",
    "\n",
    "# Constraint 8: Equipment Allocation  60%\n",
    "selected_equipment = [\"Barbell\", \"Dumbbell\", \"Machine\", \"Cable\", \"E-Z Curl Bar\", \"Bands\"]\n",
    "equipment_alloc = sum(x[i] for i in exercises if any(eq in equipment[i] for eq in selected_equipment))\n",
    "model.addConstr(equipment_alloc >= 0.60, \"Equipment_Min\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 12.0.0 build v12.0.0rc1 (win64 - Windows 11.0 (26100.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i7-9750H CPU @ 2.60GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 6 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Optimize a model with 28 rows, 2637 columns and 16472 nonzeros\n",
      "Model fingerprint: 0xb635e1ff\n",
      "Coefficient statistics:\n",
      "  Matrix range     [2e-01, 3e+00]\n",
      "  Objective range  [3e-01, 1e+00]\n",
      "  Bounds range     [5e-02, 5e-02]\n",
      "  RHS range        [5e-03, 1e+00]\n",
      "Presolve removed 1 rows and 0 columns\n",
      "Presolve time: 0.01s\n",
      "Presolved: 27 rows, 2637 columns, 14198 nonzeros\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    1.0000000e+00   2.805000e+00   0.000000e+00      0s\n",
      "      38    7.6660594e-01   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 38 iterations and 0.03 seconds (0.01 work units)\n",
      "Optimal objective  7.666059373e-01\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7666059373071197"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solve the optimization problem\n",
    "model.optimize()\n",
    "\n",
    "# Extract and display the optimal hypertrophy rating\n",
    "optimal_hypertrophy = model.objVal if model.status == GRB.OPTIMAL else None\n",
    "optimal_hypertrophy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/selvinfurtado01/operational_reserach/refs/heads/main/updated_gym_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.optimize import linprog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.00015316681088295425, array([0.]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Define the objective function coefficients (Hypertrophy Rating)\n",
    "c = [-hr for hr in df[\"Hypertrophy Rating\"].tolist()]  # Negative for maximization\n",
    "\n",
    "# Define inequality constraints (A_ub * x <= b_ub)\n",
    "A_ub = []  # Coefficients for inequality constraints\n",
    "b_ub = []  # Upper bounds\n",
    "\n",
    "# Constraint 1: Total Allocation Must Sum to 1 (Equality constraint)\n",
    "A_eq = [[1] * len(df)]  # Sum of all exercise proportions must equal 1\n",
    "b_eq = [1]\n",
    "\n",
    "# Constraint 2: Upper bound of each exercise proportion ( 0.05)\n",
    "bounds = [(0, 0.05) for _ in range(len(df))]\n",
    "\n",
    "# Constraint 5: Stimulus-to-Fatigue Ratio (Original: SFR  0.55)\n",
    "A_ub.append(df[\"Stimulus-to-Fatigue\"].tolist())\n",
    "b_ub.append(0.55)\n",
    "\n",
    "# Solve the original LP\n",
    "result_original = linprog(c, A_ub=A_ub, b_ub=b_ub, A_eq=A_eq, b_eq=b_eq, bounds=bounds, method=\"highs\")\n",
    "\n",
    "# Constraint 5 Relaxed: SFR  0.551\n",
    "b_ub[-1] = 0.551  # Increase the constraint limit by 0.001\n",
    "\n",
    "# Solve the relaxed LP\n",
    "result_relaxed = linprog(c, A_ub=A_ub, b_ub=b_ub, A_eq=A_eq, b_eq=b_eq, bounds=bounds, method=\"highs\")\n",
    "\n",
    "# Calculate the improvement in hypertrophy rating\n",
    "improvement = -result_relaxed.fun - (-result_original.fun) if result_original.success and result_relaxed.success else None\n",
    "\n",
    "# Check validity: Use dual values (shadow price) if available\n",
    "shadow_price = result_original.con if result_original.success else None\n",
    "\n",
    "improvement, shadow_price\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Traps': 0.0, 'Neck': 0.0, 'Forearms': 0.0, 'Abdominals': 0.0}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the optimal exercise allocation from the previous optimization\n",
    "optimal_allocations = result_original.x if result_original.success else None\n",
    "\n",
    "# If optimization was successful, compute total allocations for the specified body parts\n",
    "if optimal_allocations is not None:\n",
    "    body_part_allocations = {\n",
    "        \"Traps\": sum(optimal_allocations[i] for i in range(len(df)) if df[\"BodyPart\"][i] == \"Traps\"),\n",
    "        \"Neck\": sum(optimal_allocations[i] for i in range(len(df)) if df[\"BodyPart\"][i] == \"Neck\"),\n",
    "        \"Forearms\": sum(optimal_allocations[i] for i in range(len(df)) if df[\"BodyPart\"][i] == \"Forearms\"),\n",
    "        \"Abdominals\": sum(optimal_allocations[i] for i in range(len(df)) if df[\"BodyPart\"][i] == \"Abdominals\"),\n",
    "    }\n",
    "else:\n",
    "    body_part_allocations = None\n",
    "\n",
    "body_part_allocations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00015316681088295425"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Increase the minimum required allocation for Traps, Neck, Forearms, and Abdominals\n",
    "increased_body_part_constraints = {\n",
    "    \"Traps\": 0.01,  # Increase from 0.005 to 0.01 (1%)\n",
    "    \"Neck\": 0.01,   # Increase from 0.005 to 0.01 (1%)\n",
    "    \"Forearms\": 0.01,  # Increase from 0.005 to 0.01 (1%)\n",
    "    \"Abdominals\": 0.05  # Increase from 0.04 to 0.05 (5%)\n",
    "}\n",
    "\n",
    "# Update the constraints in the model\n",
    "A_ub_new = A_ub.copy()\n",
    "b_ub_new = b_ub.copy()\n",
    "\n",
    "for part, new_min in increased_body_part_constraints.items():\n",
    "    A_ub_new.append([1 if df[\"BodyPart\"][i] == part else 0 for i in range(len(df))])\n",
    "    b_ub_new.append(new_min)\n",
    "\n",
    "# Solve the new LP with increased allocations\n",
    "result_increased = linprog(c, A_ub=A_ub_new, b_ub=b_ub_new, A_eq=A_eq, b_eq=b_eq, bounds=bounds, method=\"highs\")\n",
    "\n",
    "# Compare hypertrophy rating before and after\n",
    "hypertrophy_improvement = -result_increased.fun - (-result_original.fun) if result_original.success and result_increased.success else None\n",
    "\n",
    "hypertrophy_improvement\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading dataset\n",
    "gym_data_path = ('https://raw.githubusercontent.com/selvinfurtado01/operational_reserach/refs/heads/main/updated_gym_data.csv')\n",
    "gym_data = pd.read_csv(gym_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract index of Barbell Back Squats\n",
    "barbell_squats_index = gym_data[gym_data['Exercise'] == 'Barbell Back Squats'].index[0]\n",
    "\n",
    "# Copy the original hypertrophy rating\n",
    "original_hypertrophy_rating = gym_data.loc[barbell_squats_index, 'Hypertrophy Rating']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example gym_data DataFrame\n",
    "import pandas as pd\n",
    "gym_data = pd.DataFrame({\n",
    "    'Exercise': ['Barbell Back Squats', 'Bench Press', 'Deadlift'],\n",
    "    'Hypertrophy Rating': [0.5, 0.7, 0.6]\n",
    "})\n",
    "\n",
    "# Define exercises as a list of indices\n",
    "exercises = gym_data.index.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "barbell_squats_index = gym_data[gym_data['Exercise'] == 'Barbell Back Squats'].index[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 12.0.0 build v12.0.0rc1 (win64 - Windows 11.0 (26100.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i7-9750H CPU @ 2.60GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 6 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Optimize a model with 3 rows, 3 columns and 3 nonzeros\n",
      "Model fingerprint: 0x1c7a0b7f\n",
      "Variable types: 0 continuous, 3 integer (3 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [5e-01, 7e-01]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+00]\n",
      "Found heuristic solution: objective 1.8000000\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 1 (of 12 available processors)\n",
      "\n",
      "Solution count 1: 1.8 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.800000000000e+00, best bound 1.800000000000e+00, gap 0.0000%\n"
     ]
    }
   ],
   "source": [
    "# Create the Gurobi model\n",
    "model = Model(\"Hypertrophy_Optimization\")\n",
    "\n",
    "# Add decision variables for each exercise\n",
    "x = model.addVars(exercises, vtype=GRB.BINARY, name=\"x\")\n",
    "\n",
    "# Add constraints (example)\n",
    "model.addConstrs(x[i] <= 1 for i in exercises)  # Binary decision variables\n",
    "\n",
    "# Set the initial objective function\n",
    "model.setObjective(\n",
    "    quicksum(x[i] * gym_data.loc[i, 'Hypertrophy Rating'] for i in exercises),\n",
    "    GRB.MAXIMIZE\n",
    ")\n",
    "\n",
    "# Optimize the initial model\n",
    "model.optimize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 12.0.0 build v12.0.0rc1 (win64 - Windows 11.0 (26100.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i7-9750H CPU @ 2.60GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 6 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Optimize a model with 3 rows, 3 columns and 3 nonzeros\n",
      "Model fingerprint: 0x2393b0cc\n",
      "Variable types: 0 continuous, 3 integer (3 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [5e-01, 7e-01]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+00]\n",
      "\n",
      "Loaded MIP start from previous solve with objective 1.81\n",
      "\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 1 (of 12 available processors)\n",
      "\n",
      "Solution count 1: 1.81 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.810000000000e+00, best bound 1.810000000000e+00, gap 0.0000%\n",
      "Barbell Back Squats included with hypertrophy rating: 0.51\n"
     ]
    }
   ],
   "source": [
    "# Ensure consistent indexing in gym_data\n",
    "gym_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Find the index for Barbell Back Squats\n",
    "if \"Barbell Back Squats\" in gym_data['Exercise'].values:\n",
    "    barbell_squats_index = gym_data[gym_data['Exercise'] == 'Barbell Back Squats'].index[0]\n",
    "else:\n",
    "    raise ValueError(\"Barbell Back Squats not found in gym_data.\")\n",
    "\n",
    "# Sensitivity analysis: Increment hypertrophy rating until included\n",
    "increment = 0.01\n",
    "max_hypertrophy = 1.0  # Upper limit for hypertrophy rating\n",
    "included = False\n",
    "\n",
    "while not included and gym_data.loc[barbell_squats_index, 'Hypertrophy Rating'] <= max_hypertrophy:\n",
    "    # Update hypertrophy rating\n",
    "    gym_data.loc[barbell_squats_index, 'Hypertrophy Rating'] += increment\n",
    "\n",
    "    # Update objective function with the new hypertrophy ratings\n",
    "    model.setObjective(\n",
    "        quicksum(x[i] * gym_data.loc[i, 'Hypertrophy Rating'] for i in exercises),\n",
    "        GRB.MAXIMIZE\n",
    "    )\n",
    "\n",
    "    # Re-optimize\n",
    "    model.optimize()\n",
    "\n",
    "    # Check if Barbell Back Squats is included\n",
    "    if x[barbell_squats_index].x > 0:\n",
    "        included = True\n",
    "        print(f\"Barbell Back Squats included with hypertrophy rating: {gym_data.loc[barbell_squats_index, 'Hypertrophy Rating']}\")\n",
    "\n",
    "if not included:\n",
    "    print(\"Barbell Back Squats cannot be included, even with maximum hypertrophy rating.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading dataset\n",
    "gym_data_path = ('https://raw.githubusercontent.com/selvinfurtado01/operational_reserach/refs/heads/main/updated_gym_data.csv')\n",
    "gym_data = pd.read_csv(gym_data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the dataset: Index(['Exercise', 'Category', 'BodyPart', 'Equipment', 'Difficulty',\n",
      "       'Stimulus-to-Fatigue', 'Expected Time', 'Hypertrophy Rating'],\n",
      "      dtype='object')\n",
      "\n",
      "Total Allocation to Standard Equipment: 3.0000\n"
     ]
    }
   ],
   "source": [
    "# Verify the column names\n",
    "print(\"Columns in the dataset:\", gym_data.columns)\n",
    "\n",
    "# Ensure the 'Equipment' column exists and is correctly referenced\n",
    "standard_equipment = ['Barbells', 'Dumbbells', 'Machines', 'Cables', 'Bands', 'E-Z Curl Bar']\n",
    "if 'Equipment' in gym_data.columns:\n",
    "    equipment_allocation = sum(\n",
    "        x[i].x for i in exercises if gym_data.loc[i, 'Equipment'] in standard_equipment\n",
    "    )\n",
    "    print(f\"\\nTotal Allocation to Standard Equipment: {equipment_allocation:.4f}\")\n",
    "else:\n",
    "    print(\"The 'Equipment' column is missing or improperly named in the dataset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Workout Program Allocations:\n",
      "Bench Press With Short Bands: 1.0000\n",
      "Hip Lift with Band: 1.0000\n",
      "Band Good Morning (Pull Through): 1.0000\n",
      "\n",
      "Total Allocation to Standard Equipment: 3.0000\n",
      "\n",
      "Body Part Allocations:\n",
      "BodyPart\n",
      "Abdominals     344.378898\n",
      "Abductors        6.072283\n",
      "Adductors        2.934949\n",
      "Biceps          96.622704\n",
      "Calves          18.027344\n",
      "Chest          132.737954\n",
      "Forearms        14.817048\n",
      "Glutes          38.991606\n",
      "Hamstrings      48.971870\n",
      "Lats            61.983604\n",
      "Lower Back      49.383049\n",
      "Middle Back     64.560334\n",
      "Neck             2.298934\n",
      "Quadriceps     308.128500\n",
      "Shoulders      182.460707\n",
      "Traps           13.825678\n",
      "Triceps         85.855842\n",
      "Name: Hypertrophy Rating, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Analyze the optimal workout program\n",
    "if model.status == GRB.OPTIMAL:\n",
    "    print(\"Optimal Workout Program Allocations:\")\n",
    "    for i in exercises:\n",
    "        if x[i].x > 0:\n",
    "            print(f\"{gym_data.loc[i, 'Exercise']}: {x[i].x:.4f}\")\n",
    "    \n",
    "    # Analyze total allocation to standard equipment\n",
    "    standard_equipment = ['Barbells', 'Dumbbells', 'Machines', 'Cables', 'Bands', 'E-Z Curl Bar']\n",
    "    equipment_allocation = sum(x[i].x for i in exercises if gym_data.loc[i, 'Equipment'] in standard_equipment)\n",
    "    print(f\"\\nTotal Allocation to Standard Equipment: {equipment_allocation:.4f}\")\n",
    "\n",
    "    # Analyze allocation by body part\n",
    "    body_part_allocations = gym_data.groupby('BodyPart')['Hypertrophy Rating'].sum()\n",
    "    print(\"\\nBody Part Allocations:\")\n",
    "    print(body_part_allocations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading File data\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/selvinfurtado01/operational_reserach/refs/heads/main/updated_gym_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gurobipy import Model, GRB\n",
    "\n",
    "# Initialize the optimization model\n",
    "model = Model(\"Optimal_Hypertrophy\")\n",
    "\n",
    "# Extract necessary data from the dataset\n",
    "exercises = df.index.tolist()  # Exercise indices (0 to 2636)\n",
    "hypertrophy = df[\"Hypertrophy Rating\"].tolist()  # Hypertrophy ratings\n",
    "sfr = df[\"Stimulus-to-Fatigue\"].tolist()  # SFR values\n",
    "body_part = df[\"BodyPart\"].tolist()  # Target muscle groups\n",
    "difficulty = df[\"Difficulty\"].tolist()  # Exercise difficulty levels\n",
    "category = df[\"Category\"].tolist()  # Training category (Powerlifting, Strongman, etc.)\n",
    "equipment = df[\"Equipment\"].fillna(\"Other\").tolist()  # Fill missing equipment values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gurobi.Constr *Awaiting Model Update*>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define decision variables (exercise proportions)\n",
    "x = model.addVars(exercises, lb=0, ub=0.05, vtype=GRB.CONTINUOUS, name=\"x\")\n",
    "\n",
    "# Objective Function: Maximize Hypertrophy Rating\n",
    "model.setObjective(sum(hypertrophy[i] * x[i] for i in exercises), GRB.MAXIMIZE)\n",
    "\n",
    "# Constraint 1: Total Allocation Must Sum to 1 (100% of the program)\n",
    "model.addConstr(sum(x[i] for i in exercises) == 1, \"Total_Allocation\")\n",
    "\n",
    "# Constraint 2: Body Part Allocation Constraints\n",
    "body_part_constraints = {\n",
    "    \"Traps\": 0.005, \"Neck\": 0.005, \"Forearms\": 0.005, \"Abdominals\": 0.04\n",
    "}\n",
    "\n",
    "# Ensure each required body part gets at least its minimum allocation\n",
    "for part, min_alloc in body_part_constraints.items():\n",
    "    model.addConstr(sum(x[i] for i in exercises if body_part[i] == part) >= min_alloc, f\"Min_{part}\")\n",
    "\n",
    "# General muscle groups should be at least 2.5%\n",
    "muscle_groups = set(body_part) - set(body_part_constraints.keys())\n",
    "for group in muscle_groups:\n",
    "    model.addConstr(sum(x[i] for i in exercises if body_part[i] == group) >= 0.025, f\"Min_{group}\")\n",
    "\n",
    "\n",
    "# Constraint 8: Equipment Allocation  60%\n",
    "selected_equipment = [\"Barbell\", \"Dumbbell\", \"Machine\", \"Cable\", \"E-Z Curl Bar\", \"Bands\"]\n",
    "equipment_alloc = sum(x[i] for i in exercises if any(eq in equipment[i] for eq in selected_equipment))\n",
    "model.addConstr(equipment_alloc >= 0.60, \"Equipment_Min\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 12.0.0 build v12.0.0rc1 (win64 - Windows 11.0 (26100.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i7-9750H CPU @ 2.60GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 6 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Optimize a model with 19 rows, 2637 columns and 6580 nonzeros\n",
      "Model fingerprint: 0x58e61afe\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [3e-01, 1e+00]\n",
      "  Bounds range     [5e-02, 5e-02]\n",
      "  RHS range        [5e-03, 1e+00]\n",
      "Presolve time: 0.01s\n",
      "Presolved: 19 rows, 2637 columns, 6580 nonzeros\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    1.0000000e+00   1.305000e+00   0.000000e+00      0s\n",
      "      14    8.5703576e-01   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 14 iterations and 0.02 seconds (0.00 work units)\n",
      "Optimal objective  8.570357586e-01\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8570357585549997"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solve the optimization problem\n",
    "model.optimize()\n",
    "\n",
    "# Extract and display the optimal hypertrophy rating\n",
    "optimal_hypertrophy = model.objVal if model.status == GRB.OPTIMAL else None\n",
    "optimal_hypertrophy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the primal model\n",
    "primal_model = Model(\"Hypertrophy Optimization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ratings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Primal Decision variables: proportion of each exercise in the workout program\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m primal_vars \u001b[38;5;241m=\u001b[39m primal_model\u001b[38;5;241m.\u001b[39maddVars(\u001b[38;5;28mlen\u001b[39m(\u001b[43mratings\u001b[49m), lb\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, ub\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Primal Objective: Maximize the total hypertrophy rating\u001b[39;00m\n\u001b[0;32m      5\u001b[0m primal_model\u001b[38;5;241m.\u001b[39msetObjective(\u001b[38;5;28msum\u001b[39m(primal_vars[i] \u001b[38;5;241m*\u001b[39m ratings[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(ratings))), GRB\u001b[38;5;241m.\u001b[39mMAXIMIZE)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ratings' is not defined"
     ]
    }
   ],
   "source": [
    "# Primal Decision variables: proportion of each exercise in the workout program\n",
    "primal_vars = primal_model.addVars(len(ratings), lb=0, ub=1, name=\"x\")\n",
    "\n",
    "# Primal Objective: Maximize the total hypertrophy rating\n",
    "primal_model.setObjective(sum(primal_vars[i] * ratings[i] for i in range(len(ratings))), GRB.MAXIMIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gurobi.Constr *Awaiting Model Update*>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Primal Constraint 1: No single exercise > 5% of total\n",
    "for i in range(len(ratings)):\n",
    "    primal_model.addConstr(primal_vars[i] <= 0.05, name=f\"max_exercise_{i}\")\n",
    "\n",
    "# Primal Constraint 2: Minimum allocation for each body part\n",
    "body_part_min = {\n",
    "    \"Traps\": 0.005, \"Neck\": 0.005, \"Forearms\": 0.005, \"Abdominals\": 0.04,\n",
    "    \"default\": 0.025  # Default for all other body parts\n",
    "}\n",
    "for body_part in body_parts:\n",
    "    min_alloc = body_part_min.get(body_part, body_part_min[\"default\"])\n",
    "    primal_model.addConstr(\n",
    "        sum(primal_vars[i] for i in range(len(ratings)) if gym_data.loc[i, \"BodyPart\"] == body_part) >= min_alloc,\n",
    "        name=f\"min_bodypart_{body_part}\"\n",
    "    )\n",
    "\n",
    "# Primal Constraint 8: Equipment usage > 60%\n",
    "equipment_mask = [1 if gym_data.loc[i, \"Equipment\"] in equipment_types else 0 for i in range(len(ratings))]\n",
    "primal_model.addConstr(\n",
    "    sum(primal_vars[i] * equipment_mask[i] for i in range(len(ratings))) >= 0.6,\n",
    "    name=\"equipment_usage\"\n",
    ")\n",
    "\n",
    "# Primal Constraint: Total allocation = 100%\n",
    "primal_model.addConstr(sum(primal_vars[i] for i in range(len(ratings))) == 1.0, name=\"total_allocation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 12.0.0 build v12.0.0rc1 (mac64[x86] - Darwin 20.6.0 20G95)\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-5350U CPU @ 1.80GHz\n",
      "Thread count: 2 physical cores, 4 logical processors, using up to 4 threads\n",
      "\n",
      "Optimize a model with 2656 rows, 2637 columns and 8008 nonzeros\n",
      "Model fingerprint: 0xb2b84198\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [3e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [5e-03, 1e+00]\n",
      "Presolve removed 2637 rows and 0 columns\n",
      "Presolve time: 0.13s\n",
      "Presolved: 19 rows, 2637 columns, 5371 nonzeros\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    1.0000000e+00   1.905000e+00   0.000000e+00      0s\n",
      "      13    7.1419485e-01   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 13 iterations and 0.19 seconds (0.00 work units)\n",
      "Optimal objective  7.141948453e-01\n"
     ]
    }
   ],
   "source": [
    "# Optimize the primal model\n",
    "primal_model.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 12.0.0 build v12.0.0rc1 (mac64[x86] - Darwin 20.6.0 20G95)\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-5350U CPU @ 1.80GHz\n",
      "Thread count: 2 physical cores, 4 logical processors, using up to 4 threads\n",
      "\n",
      "Optimize a model with 2637 rows, 2656 columns and 8008 nonzeros\n",
      "Model fingerprint: 0xff82a557\n",
      "Coefficient statistics:\n",
      "  Matrix range     [5e-02, 1e+00]\n",
      "  Objective range  [5e-03, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [3e-01, 1e+00]\n",
      "Presolve removed 2637 rows and 2656 columns\n",
      "Presolve time: 0.04s\n",
      "Presolve: All rows and columns removed\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    3.0684991e-01   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 0 iterations and 0.05 seconds (0.00 work units)\n",
      "Optimal objective  3.068499140e-01\n"
     ]
    }
   ],
   "source": [
    "# Formulate and solve the dual problem\n",
    "# Dual model initialization\n",
    "dual_model = Model(\"Hypertrophy Dual Optimization\")\n",
    "\n",
    "# Dual variables\n",
    "dual_max_exercise = dual_model.addVars(len(ratings), lb=0, name=\"dual_max_exercise\")\n",
    "dual_min_bodypart = dual_model.addVars(body_parts, lb=0, name=\"dual_min_bodypart\")\n",
    "dual_equipment = dual_model.addVar(lb=0, name=\"dual_equipment\")\n",
    "dual_total_allocation = dual_model.addVar(lb=0, name=\"dual_total_allocation\")\n",
    "\n",
    "# Dual Objective: Minimize the combined dual variables\n",
    "dual_model.setObjective(\n",
    "    sum(0.05 * dual_max_exercise[i] for i in range(len(ratings))) +\n",
    "    sum(body_part_min.get(bp, body_part_min[\"default\"]) * dual_min_bodypart[bp] for bp in body_parts) +\n",
    "    0.6 * dual_equipment +\n",
    "    dual_total_allocation,\n",
    "    GRB.MINIMIZE\n",
    ")\n",
    "\n",
    "# Dual Constraints: Ensure each exercise's contribution is covered\n",
    "for i in range(len(ratings)):\n",
    "    exercise_body_part = gym_data.loc[i, \"BodyPart\"]\n",
    "    exercise_equipment = 1 if gym_data.loc[i, \"Equipment\"] in equipment_types else 0\n",
    "\n",
    "    dual_model.addConstr(\n",
    "        0.05 * dual_max_exercise[i] +\n",
    "        dual_min_bodypart[exercise_body_part] +\n",
    "        exercise_equipment * dual_equipment +\n",
    "        dual_total_allocation >= ratings[i],\n",
    "        name=f\"dual_constraint_{i}\"\n",
    "    )\n",
    "\n",
    "# Optimize the dual model\n",
    "dual_model.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Dual Value: 0.3068\n"
     ]
    }
   ],
   "source": [
    "# Extract dual results\n",
    "if dual_model.status == GRB.OPTIMAL:\n",
    "    optimal_dual_value = dual_model.objVal\n",
    "    print(f\"Optimal Dual Value: {optimal_dual_value:.4f}\")\n",
    "else:\n",
    "    print(\"Dual optimization failed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The primal model is generally easier to solve and interpret in this scenario because it directly provides the allocation of exercises to the workout program. However, the dual model might be preferred if:\n",
    "\n",
    "#### 1. The primal has many variables but relatively few constraints.\n",
    "#### 2. Insights into constraint sensitivities or resource allocations are needed.\n",
    "\n",
    "#### For the dataset in this problem, where constraints (e.g., body parts, equipment) are fewer than the number of exercises, the dual model might be computationally simpler but harder to interpret directly in terms of exercise allocations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
